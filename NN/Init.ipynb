{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5747,  0.2571,  0.3876, -0.6789],\n",
      "         [-0.1274, -0.4648,  0.3675, -0.1077],\n",
      "         [ 0.3852, -0.4019,  0.1990, -0.3258]],\n",
      "\n",
      "        [[ 0.4448, -0.3108,  0.1496,  0.6808],\n",
      "         [ 0.0218, -0.4473,  0.5176, -0.2639],\n",
      "         [ 0.1753, -0.5661, -0.7415,  0.5213]]])\n"
     ]
    }
   ],
   "source": [
    "# Xavier均匀分布\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# xavier初始化方法中服从均匀分布U(−a,a) ，分布的参数a = gain * sqrt(6/(fan_in+fan_out))\n",
    "# gain 用nn.init.calculate_gain根据激活函数类型计算得到\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "torch.nn.init.xavier_uniform_(tensor, gain=nn.init.calculate_gain('relu'))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6021, -0.1074, -0.5141,  0.0402],\n",
      "         [ 1.0203,  0.4095,  0.0646, -0.1003],\n",
      "         [ 0.3833, -0.2419, -0.0603, -0.6046]],\n",
      "\n",
      "        [[ 0.3286, -0.0358, -0.1377, -0.1623],\n",
      "         [ 0.5104,  0.5120, -0.4009,  0.6358],\n",
      "         [ 0.3231, -0.0010,  0.6510, -0.5581]]])\n"
     ]
    }
   ],
   "source": [
    "# Xavier正态分布\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# xavier初始化方法中服从xavier初始化方法中服从正态分布\n",
    "# mean=0,std = gain * sqrt(2/(fan_in + fan_out)), 采样区间[-3*std,3*std]\n",
    "# gain 用nn.init.calculate_gain根据激活函数类型计算得到\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "torch.nn.init.xavier_normal_(tensor, gain=nn.init.calculate_gain('relu'))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1286, -0.3236, -0.6906, -0.2938],\n",
      "         [-0.6627,  0.5871, -0.3764,  0.3403],\n",
      "         [ 0.0120, -0.4513, -0.4691, -0.1984]],\n",
      "\n",
      "        [[-0.1422, -0.1054, -0.1216, -0.5824],\n",
      "         [-0.0509, -0.4790,  0.2633, -0.1286],\n",
      "         [ 0.4830,  0.3720, -0.0142, -0.1052]]])\n"
     ]
    }
   ],
   "source": [
    "# kaiming均匀分布\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "# 此为均匀分布，U～（-bound, bound）, bound = sqrt(6/(1+a^2)*fan_in)\n",
    "# 其中，a为激活函数的负半轴的斜率(only used with 'leaky_relu')，relu是0\n",
    "# mode 可选为fan_in 或 fan_out, fan_in使正向传播时，方差一致; fan_out使反向传播时，方差一致\n",
    "# nonlinearity 可选 relu 和 leaky_relu ，默认值为leaky_relu\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "nn.init.kaiming_uniform_(tensor, mode='fan_in', nonlinearity='relu')\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3748e-01,  3.0131e-01, -6.2661e-01, -1.3470e-01],\n",
      "         [ 1.1400e-02, -3.6569e-01, -2.9593e-02, -7.9921e-01],\n",
      "         [ 3.3311e-01,  8.9565e-02,  7.8913e-01, -6.0007e-01]],\n",
      "\n",
      "        [[ 2.4171e-01, -5.2970e-01,  8.1883e-01,  1.5488e-01],\n",
      "         [-5.1811e-01, -1.1454e+00,  1.5013e-01,  8.5769e-01],\n",
      "         [-3.8533e-01, -1.5154e-02, -6.4801e-04,  7.5629e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# kaiming正态分布\n",
    "torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "nn.init.kaiming_normal_(tensor, mode='fan_out', nonlinearity='relu')\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9856,  0.7861,  0.4006,  0.6858],\n",
      "         [ 0.9115,  0.3863, -0.7667, -0.2514],\n",
      "         [ 0.7091,  0.7564,  0.4763, -0.0081]],\n",
      "\n",
      "        [[ 0.1622,  0.9549, -0.0225,  0.2134],\n",
      "         [-0.7551, -0.3851, -0.7736, -0.0865],\n",
      "         [ 0.2661, -0.0135, -0.8620, -0.7685]]])\n"
     ]
    }
   ],
   "source": [
    "# 均匀分布初始化\n",
    "# 均匀分布(a, b)\n",
    "\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "torch.nn.init.uniform_(tensor, a=-1, b=1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.9547e+00, -1.7794e-03,  1.1247e+00, -3.5932e-01],\n",
      "         [ 3.7419e-01,  6.1432e-01, -3.0871e-01, -5.0959e-01],\n",
      "         [-1.4301e+00, -1.9513e-01,  2.5254e+00, -1.0865e+00]],\n",
      "\n",
      "        [[-5.6728e-01,  2.1242e+00,  1.1560e+00, -3.1823e-01],\n",
      "         [-1.5416e+00,  8.6812e-01, -1.6957e+00, -1.4686e-01],\n",
      "         [-1.1974e+00, -2.1354e-01, -1.3344e+00, -2.4256e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# 正态分布初始化\n",
    "# 使值服从正态分布N(mean, std)，默认值为0，1\n",
    "\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "torch.nn.init.normal_(tensor, mean=0, std=1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]]])\n"
     ]
    }
   ],
   "source": [
    "# 常数初始化\n",
    "# 使值为常数val nn.init.constant_(w, 0.3)\n",
    "\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "torch.nn.init.constant_(tensor, 3)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 单位矩阵初始化\n",
    "# 将二维tensor初始化为单位矩阵（the identity matrix）\n",
    "\n",
    "tensor = torch.zeros(2, 3)\n",
    "tensor1 = torch.zeros(3, 3)\n",
    "torch.nn.init.eye_(tensor)\n",
    "torch.nn.init.eye_(tensor1)\n",
    "print(tensor)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6332, -0.3543, -0.6882],\n",
      "        [-0.7220, -0.0502,  0.6901],\n",
      "        [-0.2790,  0.9338, -0.2240]])\n",
      "tensor([[ 1.0000e+00, -1.1514e-07, -1.0761e-07],\n",
      "        [-1.1514e-07,  1.0000e+00,  4.9114e-08],\n",
      "        [-1.0761e-07,  4.9114e-08,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# 正交初始化\n",
    "# 使得tensor是正交的，论文:Exact solutions to the nonlinear dynamics of learning in deep linear neural networks” - Saxe, A. et al. (2013)\n",
    "tensor = torch.ones(3, 3)\n",
    "torch.nn.init.orthogonal_(tensor, gain=1)\n",
    "print(tensor)\n",
    "print(tensor.mm(tensor.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0107, -0.0065,  0.0067],\n",
      "        [-0.0078, -0.0064, -0.0129]])\n"
     ]
    }
   ],
   "source": [
    "# 稀疏初始化\n",
    "# torch.nn.init.sparse_(tensor, sparsity, std=0.01)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "tensor = torch.tensor([ [1, 2, 3],\n",
    "                        [2, 3, 4],\n",
    "                        [4, 5, 6] ], dtype=torch.float)\n",
    "\n",
    "# 从正态分布N～（0. std）中进行稀疏化，使每一个column有一部分为0\n",
    "# sparsity 每一个column稀疏的比例，即为0的比例\n",
    "\n",
    "nn.init.sparse_(tensor, sparsity=0.1)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
