{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600481592223",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.0321, 0.0871, 0.2369, 0.6439])\ntensor([[1.],\n        [2.],\n        [3.],\n        [4.]])\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.]])\ntensor([1., 2., 3., 4.])\ntensor([0.0321, 0.0871, 0.2369, 0.6439])\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4], dtype = torch.float)\n",
    "print(torch.softmax(a, dim=0))\n",
    "\n",
    "\n",
    "a = torch.unsqueeze(a, dim=1)\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "print(a)\n",
    "print(m(a))\n",
    "\n",
    "a = torch.squeeze(a, dim=1)\n",
    "m = torch.nn.Softmax(dim=0)\n",
    "print(a)\n",
    "print(m(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([32, 5])\ntensor([[0.2797, 0.1261, 0.1769, 0.3503, 0.0670],\n        [0.2544, 0.2684, 0.0621, 0.0433, 0.3719],\n        [0.5148, 0.1591, 0.0350, 0.0420, 0.2490],\n        [0.3425, 0.2680, 0.1393, 0.1411, 0.1091],\n        [0.4370, 0.0301, 0.2428, 0.1009, 0.1892],\n        [0.5858, 0.1862, 0.0780, 0.0222, 0.1279],\n        [0.1838, 0.0161, 0.0608, 0.6250, 0.1143],\n        [0.2588, 0.0906, 0.2599, 0.3393, 0.0514],\n        [0.4596, 0.2959, 0.0300, 0.1644, 0.0501],\n        [0.1925, 0.2015, 0.0228, 0.2341, 0.3492],\n        [0.2926, 0.1672, 0.1070, 0.2004, 0.2328],\n        [0.3492, 0.1506, 0.2867, 0.0491, 0.1643],\n        [0.0202, 0.4887, 0.0199, 0.0511, 0.4201],\n        [0.2694, 0.5388, 0.0358, 0.1367, 0.0194],\n        [0.1460, 0.2945, 0.1663, 0.2835, 0.1097],\n        [0.0211, 0.0954, 0.5828, 0.0878, 0.2129],\n        [0.3008, 0.2293, 0.2661, 0.1716, 0.0322],\n        [0.4209, 0.4067, 0.0599, 0.0855, 0.0271],\n        [0.2152, 0.0554, 0.3402, 0.2077, 0.1816],\n        [0.2258, 0.0622, 0.0202, 0.2494, 0.4424],\n        [0.0132, 0.3913, 0.2050, 0.2834, 0.1071],\n        [0.2450, 0.3063, 0.0442, 0.3308, 0.0737],\n        [0.0444, 0.1812, 0.5918, 0.1751, 0.0075],\n        [0.0836, 0.3343, 0.1396, 0.2072, 0.2353],\n        [0.0304, 0.3191, 0.5030, 0.0875, 0.0600],\n        [0.2226, 0.3111, 0.0529, 0.1887, 0.2247],\n        [0.0574, 0.3819, 0.0518, 0.3116, 0.1974],\n        [0.0819, 0.5212, 0.0683, 0.1143, 0.2143],\n        [0.0354, 0.5670, 0.0757, 0.2975, 0.0244],\n        [0.1184, 0.0775, 0.1089, 0.3881, 0.3071],\n        [0.2787, 0.0619, 0.0698, 0.5081, 0.0815],\n        [0.1639, 0.1809, 0.4532, 0.1146, 0.0874]])\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn((32, 5))\n",
    "print(a.size())\n",
    "print(torch.softmax(a, dim=1))"
   ]
  }
 ]
}