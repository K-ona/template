{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.0653e-38, 1.0194e-38, 8.4490e-39],\n        [9.6429e-39, 8.4490e-39, 9.6429e-39],\n        [9.2755e-39, 1.0286e-38, 9.0919e-39],\n        [8.9082e-39, 9.2755e-39, 8.4490e-39],\n        [1.0194e-38, 9.0919e-39, 8.4490e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.0549, 0.0480, 0.5447],\n        [0.8441, 0.5198, 0.0073],\n        [0.8776, 0.5161, 0.5265],\n        [0.4600, 0.7444, 0.3639],\n        [0.3632, 0.0863, 0.3706]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype = torch.float64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=torch.int32)\ntensor([1, 2])\ntensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(np.arange(12))\n",
    "print(x)\n",
    "x = torch.tensor([1, 2])\n",
    "print(x)\n",
    "x = torch.tensor(1.)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\ntensor([[ 0.8543, -0.3033,  1.3905],\n        [ 0.5786, -0.1102,  0.2065],\n        [-0.7074,  0.6953, -1.8976],\n        [ 0.1590, -0.8507,  1.5624],\n        [ 1.2459,  0.8895, -0.7093]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype = torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.8543, -0.3033,  1.3905],\n",
      "        [ 0.5786, -0.1102,  0.2065],\n",
      "        [-0.7074,  0.6953, -1.8976],\n",
      "        [ 0.1590, -0.8507,  1.5624],\n",
      "        [ 1.2459,  0.8895, -0.7093]])\n",
      "tensor([[ 1.2500,  0.3228,  1.5599],\n",
      "        [ 1.0046,  0.2774,  0.9113],\n",
      "        [-0.5697,  1.2437, -1.3235],\n",
      "        [ 0.4213, -0.6352,  1.7264],\n",
      "        [ 2.2224,  1.0408, -0.0348]])\n",
      "tensor([[ 0.8543, -0.3033,  1.3905],\n",
      "        [ 0.5786, -0.1102,  0.2065],\n",
      "        [-0.7074,  0.6953, -1.8976],\n",
      "        [ 0.1590, -0.8507,  1.5624],\n",
      "        [ 1.2459,  0.8895, -0.7093]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x.add(y))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.2500,  0.3228,  1.5599],\n        [ 1.0046,  0.2774,  0.9113],\n        [-0.5697,  1.2437, -1.3235],\n        [ 0.4213, -0.6352,  1.7264],\n        [ 2.2224,  1.0408, -0.0348]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.2751, -2.5139,  1.4946, -0.7663],\n        [-1.3347, -2.0894,  1.9610, -1.8249],\n        [ 1.5732, -1.0853,  1.1302, -1.3456],\n        [-0.0648,  0.4415, -1.3854, -0.2662]])\ntensor([ 0.2751, -2.5139,  1.4946, -0.7663, -1.3347, -2.0894,  1.9610, -1.8249,\n         1.5732, -1.0853,  1.1302, -1.3456, -0.0648,  0.4415, -1.3854, -0.2662])\ntensor([[ 0.2751, -2.5139,  1.4946, -0.7663, -1.3347, -2.0894,  1.9610, -1.8249],\n        [ 1.5732, -1.0853,  1.1302, -1.3456, -0.0648,  0.4415, -1.3854, -0.2662]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "z = x.view(2, -1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.4267,  1.5365,  1.0220],\n        [-0.2331, -0.3418, -0.4315]])\n-0.34176233410835266\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(x[1, 1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]]\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4, 4)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.],\n        [2., 2., 2., 2.]])\n[[2. 2. 2. 2.]\n [2. 2. 2. 2.]\n [2. 2. 2. 2.]\n [2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.5733, 2.5365, 2.0220],\n        [0.7669, 0.6582, 0.5685]], device='cuda:0')\ntensor([[0.5733, 2.5365, 2.0220],\n        [0.7669, 0.6582, 0.5685]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\ntensor([[ 0.2729,  0.7477],\n        [-4.1483,  5.0544]], requires_grad=True)\nTrue\ntensor(43.3887, grad_fn=<SumBackward0>)\n<SumBackward0 object at 0x000001DD45CCE848>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a)\n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a * a).sum()\n",
    "print(b)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\nTrue\ntensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\nTrue\ntensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>)\nTrue\ntensor(27., grad_fn=<MeanBackward0>)\nTrue\ntensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.requires_grad)\n",
    "\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "print(z.requires_grad)\n",
    "\n",
    "mean = z.mean()\n",
    "print(mean)\n",
    "print(mean.requires_grad)\n",
    "\n",
    "mean.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.1881, -0.9697, -0.5909], requires_grad=True)\ntensor([ 192.6114, -992.9422, -605.0761], grad_fn=<MulBackward0>)\ntensor(-468.4690, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x * 2\n",
    "# 默认二范数\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)\n",
    "\n",
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.1881, -0.9697, -0.5909], requires_grad=True)\ntensor([341.3333, 341.3333, 341.3333])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype = torch.float)\n",
    "# y.backward(v)\n",
    "# print(x.grad)\n",
    "\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nFalse\ntensor([True, True, True])\ntensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x == y)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "\n",
    "        self.ff1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.ff2 = nn.Linear(120, 84)\n",
    "        self.ff3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "\n",
    "        x = x.view(-1, self.num_flat_featrues(x))\n",
    "        x = F.relu(self.ff1(x))\n",
    "        x = F.relu(self.ff2(x))\n",
    "        x = self.ff3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_featrues(self, x):\n",
    "        size = x.size()[1:]\n",
    "        res = 1\n",
    "        for s in size:\n",
    "            res *= s\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeuralNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (ff1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (ff2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (ff3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([6, 1, 3, 3])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 576])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetwork()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(params.__len__())\n",
    "for p in params:\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0959,  0.0837, -0.0397,  0.0508,  0.0516, -0.0667, -0.0193, -0.0601,\n          0.0252, -0.0099]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.6198, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<MseLossBackward object at 0x000001DD44ABD708>\n<AddmmBackward object at 0x000001DD45A39588>\n<AccumulateGrad object at 0x000001DD45B9F448>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad after backward\ntensor([ 0.0078, -0.0107,  0.0156,  0.0109, -0.0041, -0.0354])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[ 0.0823,  0.2070, -0.2050],\n          [ 0.1239, -0.2487,  0.0959],\n          [-0.2580, -0.1075, -0.0326]]],\n\n\n        [[[ 0.3119, -0.2846,  0.1717],\n          [ 0.2668, -0.2483,  0.0684],\n          [-0.1244,  0.0320,  0.3458]]],\n\n\n        [[[-0.0043, -0.0786, -0.1916],\n          [ 0.2110,  0.2002,  0.1834],\n          [ 0.2470, -0.1661, -0.2878]]],\n\n\n        [[[-0.0544, -0.3253, -0.3291],\n          [-0.2136, -0.1472,  0.2057],\n          [ 0.0489,  0.1800,  0.3317]]],\n\n\n        [[[-0.2338, -0.2033,  0.1565],\n          [ 0.0554,  0.2191,  0.2251],\n          [-0.3129,  0.2001,  0.0947]]],\n\n\n        [[[ 0.0800, -0.0114,  0.1360],\n          [-0.1003, -0.0791,  0.2523],\n          [ 0.0248,  0.0159,  0.3524]]]])\ntensor([[[[ 0.0778,  0.2105, -0.2027],\n          [ 0.1147, -0.2271,  0.1038],\n          [-0.2636, -0.0900, -0.0329]]],\n\n\n        [[[ 0.3161, -0.2828,  0.1615],\n          [ 0.2819, -0.2262,  0.0564],\n          [-0.1326,  0.0418,  0.3630]]],\n\n\n        [[[-0.0023, -0.0792, -0.1769],\n          [ 0.2071,  0.2048,  0.1790],\n          [ 0.2545, -0.1790, -0.2825]]],\n\n\n        [[[-0.0487, -0.3354, -0.3286],\n          [-0.2097, -0.1486,  0.1685],\n          [ 0.0411,  0.1866,  0.3471]]],\n\n\n        [[[-0.2167, -0.2116,  0.1619],\n          [ 0.0501,  0.2414,  0.2324],\n          [-0.3069,  0.2012,  0.1027]]],\n\n\n        [[[ 0.0744, -0.0011,  0.1304],\n          [-0.0978, -0.0717,  0.2542],\n          [ 0.0267,  0.0118,  0.3778]]]])\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "print(list(net.parameters())[0].data)\n",
    "\n",
    "\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * lr)\n",
    "\n",
    "print(list(net.parameters())[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()"
   ]
  }
 ]
}