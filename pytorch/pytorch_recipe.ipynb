{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd04ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3, 4]])\ntensor([[1],\n        [2],\n        [3],\n        [4]])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.unsqueeze(dim)\n",
    "# 插入维度1在指定dim上\n",
    "# 同torch.unsqueeze(input, dim) → Tensor\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x.unsqueeze(0))\n",
    "print(x.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\nFalse\nTrue\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.contiguous(memory_format=torch.contiguous_format)\n",
    "# view 操作依赖于内存是连续的\n",
    "\n",
    "import torch\n",
    "x = torch.ones(10, 10)\n",
    "print(x.is_contiguous())  # True\n",
    "print(x.view(5, -1).is_contiguous()) # True\n",
    "print(x.view(2, -1).transpose(0, 1).is_contiguous()) # False\n",
    "print(x.transpose(0, 1).is_contiguous())  # False\n",
    "print(x.transpose(0, 1).contiguous().is_contiguous())  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'num_features' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-247e86ff312c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Buffers can be accessed as attributes using given names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'running_mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_features' is not defined"
     ]
    }
   ],
   "source": [
    "# torch.nn.Module.register_buffer\n",
    "# register_buffer(name: str, tensor: Optional[torch.Tensor], persistent: bool = True) → None\n",
    "# Buffers can be accessed as attributes using given names.\n",
    "\n",
    "# torch.nn.Module.register_buffer('running_mean', torch.zeros(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([30, 20])\n<class 'torch.nn.parameter.Parameter'> torch.Size([30])\ntensor([[-5.6082e-01,  2.6110e-01, -1.3870e+00, -4.6757e-01, -6.9922e-01,\n         -4.9431e-01, -2.9007e-01, -5.4331e-04, -5.8607e-01, -9.7069e-01,\n         -5.4193e-01, -9.1854e-01, -5.4605e-01,  5.5389e-01, -1.3397e-01,\n         -1.7871e-01,  2.3373e-01, -3.5868e-01, -1.1650e-01,  1.6038e-01,\n          6.6730e-01, -2.2994e-01, -1.0970e-01,  1.4902e+00,  3.7058e-02,\n          2.6090e-01, -5.8366e-01,  5.0596e-01,  3.4243e-01, -6.3906e-01],\n        [-8.8587e-01,  1.3255e+00, -5.6382e-01,  2.6223e-01,  2.2571e-02,\n          3.2612e-01, -5.8976e-01, -5.7534e-03, -1.0274e+00, -9.7454e-02,\n         -3.5350e-01, -3.7134e-01,  9.0781e-01,  1.3150e+00, -6.9298e-01,\n          6.4488e-01,  2.0093e-01, -6.0642e-01,  1.0707e+00, -4.4424e-01,\n         -4.2605e-01, -1.2291e+00,  4.3234e-01, -2.1253e-01, -8.2090e-01,\n          8.9539e-01,  2.1255e-01,  5.9120e-01, -5.7845e-02, -4.9749e-01],\n        [ 9.6101e-02,  1.1678e+00,  1.4059e-01,  1.3240e-01, -1.0957e+00,\n         -1.2954e+00,  8.3631e-01,  5.7637e-02,  7.6324e-02, -3.5914e-01,\n         -6.2753e-01,  8.7166e-01, -1.8474e-01, -1.2067e+00,  1.8396e-01,\n          2.5459e-01,  2.2053e-01, -3.2258e-01, -1.8420e-01, -5.9307e-01,\n         -1.1448e+00,  5.2046e-01, -3.8567e-02, -1.9872e-01,  7.1913e-01,\n          2.6689e-01, -7.2954e-01, -6.7134e-01,  9.1467e-01, -3.8221e-01],\n        [ 9.1405e-03,  5.4435e-01,  8.6808e-01, -2.6227e-01,  7.7773e-01,\n          3.8470e-01, -8.3339e-01,  4.0108e-01, -1.1352e-02, -6.1221e-01,\n         -7.8698e-02,  7.0179e-01,  1.0994e+00, -5.4378e-01,  3.3912e-01,\n          7.4375e-01, -1.9326e-01,  3.7635e-02, -3.9222e-01, -7.3734e-01,\n         -3.3947e-01, -8.4357e-01, -3.3866e-01, -8.9598e-01,  2.9156e-01,\n         -9.8065e-01,  6.0964e-01,  9.8797e-01, -1.0872e+00, -9.4003e-01],\n        [-5.4854e-01, -1.9625e-01, -3.8135e-01, -6.4151e-02,  2.8267e-01,\n          2.5449e-01, -7.5455e-02,  1.0751e+00, -7.8001e-01,  1.1273e-01,\n          3.6488e-01,  4.8023e-01, -1.1657e-01, -5.2718e-01, -5.3981e-01,\n          3.0773e-01, -2.1058e-01,  4.0142e-01, -1.9725e-01,  7.9325e-01,\n          4.3226e-01, -6.8966e-01, -4.0192e-01,  4.0647e-01,  5.9395e-03,\n          2.5010e-01, -3.1780e-01, -5.2115e-01, -2.3358e-01, -6.0809e-01],\n        [-7.3648e-01,  3.2928e-01, -1.8791e-01,  7.0645e-01,  4.8258e-01,\n         -9.5523e-02,  6.2850e-01,  8.8460e-02,  4.8063e-01, -4.1530e-01,\n         -4.9692e-01,  2.7513e-02,  4.9835e-01,  3.8266e-01, -2.2328e-01,\n          7.6236e-01,  4.2318e-01,  6.6000e-01, -4.0461e-01, -4.5240e-01,\n         -2.6969e-01, -9.1228e-01, -2.4607e-01,  4.3774e-01, -7.7665e-01,\n         -2.1090e-01, -1.6485e-01,  3.9834e-01,  1.0665e+00, -3.0344e-02],\n        [-7.8616e-01, -3.1349e-01, -3.8505e-01,  1.5674e+00,  3.0500e-01,\n          2.4306e-01,  2.3641e-01,  6.6657e-01,  6.4318e-01,  5.1286e-02,\n          4.7016e-01, -3.3819e-01,  1.3174e-01,  2.6792e-01, -3.0470e-01,\n          1.2251e+00, -2.3337e-01,  7.2062e-01, -1.8462e-02,  6.4391e-01,\n         -3.8114e-01, -9.2137e-01,  8.1321e-01,  5.3692e-01, -8.2565e-01,\n          2.6965e-01, -9.4099e-01, -1.0120e-01,  4.3509e-01,  4.1399e-01],\n        [-1.8465e+00,  1.1063e-01, -2.2568e-01,  9.2257e-01,  4.5619e-01,\n          1.3095e-01,  5.9449e-01,  3.5389e-01,  1.2017e-01, -7.8874e-01,\n          1.6949e-01, -5.8676e-01, -8.0493e-01,  5.5920e-01, -2.5602e-01,\n          7.5942e-01,  6.8706e-01, -1.1348e+00,  3.1875e-01, -7.1257e-01,\n         -4.8418e-01, -3.5607e-01,  1.2538e+00,  1.0267e+00, -1.2785e+00,\n          8.2653e-01,  5.9422e-01,  5.5222e-02,  1.8019e-02,  9.9817e-02],\n        [ 6.3822e-01,  5.7659e-01,  1.5780e+00, -3.7886e-01, -5.2548e-01,\n         -1.4705e-01,  7.1748e-01, -2.4491e-01,  7.4453e-01, -2.3555e-02,\n         -9.3903e-01,  4.3586e-01,  5.5119e-01,  2.0391e-01,  8.9173e-01,\n          2.5671e-01,  3.4033e-01,  1.1443e-01, -1.2211e+00,  2.4528e-01,\n         -8.7561e-01,  2.5580e-01,  4.8690e-01, -4.0387e-01,  1.7491e-01,\n         -6.8550e-01,  7.2972e-02, -1.0568e+00, -3.9719e-02,  3.5515e-01],\n        [-5.5981e-01,  4.0586e-01,  5.3449e-02,  1.8220e-01,  6.7199e-01,\n          5.0971e-01, -6.2304e-02,  8.6127e-01,  1.0093e+00, -2.9419e-01,\n         -7.4894e-01, -7.9800e-01,  2.4915e-01,  5.2465e-01,  3.2308e-01,\n          4.3915e-01, -9.5086e-01,  8.4800e-02,  1.3211e-01,  2.8115e-01,\n         -6.9636e-01, -7.1508e-01,  1.2129e+00,  2.6140e-01,  3.1102e-01,\n          8.0323e-02, -5.8779e-01, -3.0632e-02, -3.3911e-01, -1.0568e-01]],\n       grad_fn=<AddmmBackward>)\ntorch.Size([10, 30])\ntensor([-5.6082e-01,  2.6110e-01, -1.3870e+00, -4.6757e-01, -6.9922e-01,\n        -4.9431e-01, -2.9007e-01, -5.4326e-04, -5.8607e-01, -9.7069e-01,\n        -5.4193e-01, -9.1854e-01, -5.4605e-01,  5.5389e-01, -1.3397e-01,\n        -1.7871e-01,  2.3373e-01, -3.5868e-01, -1.1650e-01,  1.6038e-01,\n         6.6730e-01, -2.2994e-01, -1.0970e-01,  1.4902e+00,  3.7058e-02,\n         2.6090e-01, -5.8366e-01,  5.0596e-01,  3.4243e-01, -6.3906e-01],\n       grad_fn=<AddBackward0>)\ntorch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Module.parameters\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "model = torch.nn.Linear(20, 30)\n",
    "for param in model.parameters():\n",
    "    print(type(param), param.size())\n",
    "\n",
    "vec = torch.randn((10, 20))\n",
    "vec1 = vec[0, :]\n",
    "\n",
    "output = model(vec)\n",
    "print(output)\n",
    "print(output.size())\n",
    "\n",
    "output = model(vec1)\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1.1644, -0.9384],\n         [-1.0856,  0.3334],\n         [-1.2582,  0.7507]],\n\n        [[-1.6556,  1.3005],\n         [-1.8899,  0.8326],\n         [ 0.5181, -2.3465]]])\ntorch.return_types.max(\nvalues=tensor([[1.1644, 0.7507],\n        [0.5181, 1.3005]]),\nindices=tensor([[0, 2],\n        [2, 0]]))\ntorch.return_types.max(\nvalues=tensor([[ 1.1644,  1.3005],\n        [-1.0856,  0.8326],\n        [ 0.5181,  0.7507]]),\nindices=tensor([[0, 1],\n        [0, 1],\n        [1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.max(input, dim, keepdim)\n",
    "\n",
    "a = torch.randn(2, 3, 2)\n",
    "print(a)\n",
    "print(torch.max(a, 1))\n",
    "print(torch.max(a, 0))"
   ]
  }
 ]
}